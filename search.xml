<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Faster RCNN 详解]]></title>
    <url>%2F2018%2F03%2F11%2FFaster-RCNN-%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Girshick, Ross, et al. “Rich feature hierarchies for accurate object detection and semantic segmentation.” Proceedings of the IEEE conference on computer vision and pattern recognition. 2014. Region CNN(RCNN)可以说是利用深度学习进行目标检测的开山之作。作者Ross Girshick多次在PASCAL VOC的目标检测竞赛中折桂，2010年更带领团队获得终身成就奖，如今供职于Facebook旗下的FAIR。这篇文章思路简洁，在DPM方法多年平台期后，效果提高显著。包括本文在内的一系列目标检测算法：RCNN, Fast RCNN, Faster RCNN代表当下目标检测的前沿水平，在github都给出了基于Caffe的源码。 思想本文解决了目标检测中的两个关键问题。 问题一：速度经典的目标检测算法使用滑动窗法依次判断所有可能的区域。本文则预先提取一系列较可能是物体的候选区域，之后仅在这些候选区域上提取特征，进行判断。 问题二：训练集经典的目标检测算法在区域中提取人工设定的特征（Haar，HOG）。本文则需要训练深度网络进行特征提取。可供使用的有两个数据库：一个较大的识别库（ImageNet ILSVC 2012）：标定每张图片中物体的类别。一千万图像，1000类。一个较小的检测库（PASCAL VOC 2007）：标定每张图片中，物体的类别和位置。一万图像，20类。本文使用识别库进行预训练，而后用检测库调优参数。最后在检测库上评测。 流程RCNN算法分为4个步骤 一张图像生成1K~2K个候选区域 对每个候选区域，使用深度网络提取特征 特征送入每一类的SVM 分类器，判别是否属于该类 使用回归器精细修正候选框位置 候选区域生成使用了Selective Search1方法从一张图像生成约2000-3000个候选区域。基本思路如下： 使用一种过分割手段，将图像分割成小区域 查看现有小区域，合并可能性最高的两个区域。重复直到整张图像合并成一个区域位置 输出所有曾经存在过的区域，所谓候选区域 候选区域生成和后续步骤相对独立，实际可以使用任意算法进行。 合并规则优先合并以下四种区域： 颜色（颜色直方图）相近的 纹理（梯度直方图）相近的 合并后总面积小的 合并后，总面积在其BBOX中所占比例大的 第三条，保证合并操作的尺度较为均匀，避免一个大区域陆续“吃掉”其他小区域。 例：设有区域a-b-c-d-e-f-g-h。较好的合并方式是：ab-cd-ef-gh -&gt; abcd-efgh -&gt; abcdefgh。不好的合并方法是：ab-c-d-e-f-g-h -&gt;abcd-e-f-g-h -&gt;abcdef-gh -&gt; abcdefgh。 第四条，保证合并后形状规则。 例：左图适于合并，右图不适于合并。 上述四条规则只涉及区域的颜色直方图、纹理直方图、面积和位置。合并后的区域特征可以直接由子区域特征计算而来，速度较快。 多样化与后处理为尽可能不遗漏候选区域，上述操作在多个颜色空间中同时进行（RGB,HSV,Lab等）。在一个颜色空间中，使用上述四条规则的不同组合进行合并。所有颜色空间与所有规则的全部结果，在去除重复后，都作为候选区域输出。 作者提供了Selective Search的源码，内含较多.p文件和.mex文件，难以细查具体实现。 特征提取预处理使用深度网络提取特征之前，首先把候选区域归一化成同一尺寸227×227。此处有一些细节可做变化：外扩的尺寸大小，形变时是否保持原比例，对框外区域直接截取还是补灰。会轻微影响性能。 预训练网络结构基本借鉴Hinton 2012年在Image Net上的分类网络2，略作简化3。此网络提取的特征为4096维，之后送入一个4096-&gt;1000的全连接(fc)层进行分类。学习率0.01。 训练数据使用ILVCR 2012的全部数据进行训练，输入一张图片，输出1000维的类别标号。 调优训练网络结构同样使用上述网络，最后一层换成4096-&gt;21的全连接网络。学习率0.001，每一个batch包含32个正样本（属于20类）和96个背景。 训练数据使用PASCAL VOC 2007的训练集，输入一张图片，输出21维的类别标号，表示20类+背景。考察一个候选框和当前图像上所有标定框重叠面积最大的一个。如果重叠比例大于0.5，则认为此候选框为此标定的类别；否则认为此候选框为背景。 类别判断分类器对每一类目标，使用一个线性SVM二类分类器进行判别。输入为深度网络输出的4096维特征，输出是否属于此类。由于负样本很多，使用hard negative mining方法。正样本本类的真值标定框。负样本考察每一个候选框，如果和本类所有标定框的重叠都小于0.3，认定其为负样本 位置精修目标检测问题的衡量标准是重叠面积：许多看似准确的检测结果，往往因为候选框不够准确，重叠面积很小。故需要一个位置精修步骤。回归器对每一类目标，使用一个线性脊回归器进行精修。正则项λ=10000。输入为深度网络pool5层的4096维特征，输出为xy方向的缩放和平移。训练样本判定为本类的候选框中，和真值重叠面积大于0.6的候选框。 结果论文发表的2014年，DPM已经进入瓶颈期，即使使用复杂的特征和结构得到的提升也十分有限。本文将深度学习引入检测领域，一举将PASCAL VOC上的检测率从35.1%提升到53.7%。本文的前两个步骤（候选区域提取+特征提取）与待检测类别无关，可以在不同类之间共用。这两步在GPU上约需13秒。同时检测多类时，需要倍增的只有后两步骤（判别+精修），都是简单的线性运算，速度很快。这两步对于100K类别只需10秒。 以本论文为基础，后续的Fast RCNN和Faster RCNN在速度上有突飞猛进的发展，基本解决了PASCAL VOC上的目标检测问题。 转载来源：http://blog.csdn.net/shenxiaolu1984/article/details/51066975]]></content>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RCNN 详解]]></title>
    <url>%2F2018%2F03%2F10%2FRCNN-%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Girshick, Ross, et al. “Rich feature hierarchies for accurate object detection and semantic segmentation.” Proceedings of the IEEE conference on computer vision and pattern recognition. 2014. Region CNN(RCNN)可以说是利用深度学习进行目标检测的开山之作。作者Ross Girshick多次在PASCAL VOC的目标检测竞赛中折桂，2010年更带领团队获得终身成就奖，如今供职于Facebook旗下的FAIR。这篇文章思路简洁，在DPM方法多年平台期后，效果提高显著。包括本文在内的一系列目标检测算法：RCNN, Fast RCNN, Faster RCNN代表当下目标检测的前沿水平，在github都给出了基于Caffe的源码。 思想本文解决了目标检测中的两个关键问题。 问题一：速度经典的目标检测算法使用滑动窗法依次判断所有可能的区域。本文则预先提取一系列较可能是物体的候选区域，之后仅在这些候选区域上提取特征，进行判断。 问题二：训练集经典的目标检测算法在区域中提取人工设定的特征（Haar，HOG）。本文则需要训练深度网络进行特征提取。可供使用的有两个数据库：一个较大的识别库（ImageNet ILSVC 2012）：标定每张图片中物体的类别。一千万图像，1000类。一个较小的检测库（PASCAL VOC 2007）：标定每张图片中，物体的类别和位置。一万图像，20类。本文使用识别库进行预训练，而后用检测库调优参数。最后在检测库上评测。 流程RCNN算法分为4个步骤 一张图像生成1K~2K个候选区域 对每个候选区域，使用深度网络提取特征 特征送入每一类的SVM 分类器，判别是否属于该类 使用回归器精细修正候选框位置 候选区域生成使用了Selective Search1方法从一张图像生成约2000-3000个候选区域。基本思路如下： 使用一种过分割手段，将图像分割成小区域 查看现有小区域，合并可能性最高的两个区域。重复直到整张图像合并成一个区域位置 输出所有曾经存在过的区域，所谓候选区域 候选区域生成和后续步骤相对独立，实际可以使用任意算法进行。 合并规则优先合并以下四种区域： 颜色（颜色直方图）相近的 纹理（梯度直方图）相近的 合并后总面积小的 合并后，总面积在其BBOX中所占比例大的 第三条，保证合并操作的尺度较为均匀，避免一个大区域陆续“吃掉”其他小区域。 例：设有区域a-b-c-d-e-f-g-h。较好的合并方式是：ab-cd-ef-gh -&gt; abcd-efgh -&gt; abcdefgh。不好的合并方法是：ab-c-d-e-f-g-h -&gt;abcd-e-f-g-h -&gt;abcdef-gh -&gt; abcdefgh。 第四条，保证合并后形状规则。 例：左图适于合并，右图不适于合并。 上述四条规则只涉及区域的颜色直方图、纹理直方图、面积和位置。合并后的区域特征可以直接由子区域特征计算而来，速度较快。 多样化与后处理为尽可能不遗漏候选区域，上述操作在多个颜色空间中同时进行（RGB,HSV,Lab等）。在一个颜色空间中，使用上述四条规则的不同组合进行合并。所有颜色空间与所有规则的全部结果，在去除重复后，都作为候选区域输出。 作者提供了Selective Search的源码，内含较多.p文件和.mex文件，难以细查具体实现。 特征提取预处理使用深度网络提取特征之前，首先把候选区域归一化成同一尺寸227×227。此处有一些细节可做变化：外扩的尺寸大小，形变时是否保持原比例，对框外区域直接截取还是补灰。会轻微影响性能。 预训练网络结构基本借鉴Hinton 2012年在Image Net上的分类网络2，略作简化3。此网络提取的特征为4096维，之后送入一个4096-&gt;1000的全连接(fc)层进行分类。学习率0.01。 训练数据使用ILVCR 2012的全部数据进行训练，输入一张图片，输出1000维的类别标号。 调优训练网络结构同样使用上述网络，最后一层换成4096-&gt;21的全连接网络。学习率0.001，每一个batch包含32个正样本（属于20类）和96个背景。 训练数据使用PASCAL VOC 2007的训练集，输入一张图片，输出21维的类别标号，表示20类+背景。考察一个候选框和当前图像上所有标定框重叠面积最大的一个。如果重叠比例大于0.5，则认为此候选框为此标定的类别；否则认为此候选框为背景。 类别判断分类器对每一类目标，使用一个线性SVM二类分类器进行判别。输入为深度网络输出的4096维特征，输出是否属于此类。由于负样本很多，使用hard negative mining方法。正样本本类的真值标定框。负样本考察每一个候选框，如果和本类所有标定框的重叠都小于0.3，认定其为负样本 位置精修目标检测问题的衡量标准是重叠面积：许多看似准确的检测结果，往往因为候选框不够准确，重叠面积很小。故需要一个位置精修步骤。回归器对每一类目标，使用一个线性脊回归器进行精修。正则项λ=10000。输入为深度网络pool5层的4096维特征，输出为xy方向的缩放和平移。训练样本判定为本类的候选框中，和真值重叠面积大于0.6的候选框。 结果论文发表的2014年，DPM已经进入瓶颈期，即使使用复杂的特征和结构得到的提升也十分有限。本文将深度学习引入检测领域，一举将PASCAL VOC上的检测率从35.1%提升到53.7%。本文的前两个步骤（候选区域提取+特征提取）与待检测类别无关，可以在不同类之间共用。这两步在GPU上约需13秒。同时检测多类时，需要倍增的只有后两步骤（判别+精修），都是简单的线性运算，速度很快。这两步对于100K类别只需10秒。 以本论文为基础，后续的Fast RCNN和Faster RCNN在速度上有突飞猛进的发展，基本解决了PASCAL VOC上的目标检测问题。]]></content>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
</search>
